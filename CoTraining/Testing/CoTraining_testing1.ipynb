{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Co-Training Implementation\n",
    "**Based on the Blum and Mitchell, 1998 paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setA = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "setA = ['comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware']\n",
    "setB = ['talk.politics.misc','talk.politics.guns']\n",
    "\n",
    "newsA_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=setA)\n",
    "newsB_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=setB)\n",
    "\n",
    "newsA_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=setA)\n",
    "newsB_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=setB)\n",
    "\n",
    "newsA_y_train = newsA_train.target\n",
    "newsB_y_train = newsB_train.target\n",
    "\n",
    "newsA_y_test = newsA_test.target\n",
    "newsB_y_test = newsB_test.target\n",
    "\n",
    "vectorizerA = TfidfVectorizer()\n",
    "newsA_X_train = vectorizerA.fit_transform(newsA_train.data)\n",
    "newsA_X_test = vectorizerA.transform(newsA_test.data)\n",
    "\n",
    "vectorizerB = TfidfVectorizer()\n",
    "newsB_X_train = vectorizerB.fit_transform(newsB_train.data)\n",
    "newsB_X_test = vectorizerB.transform(newsB_test.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1181,)\n",
      "(1181, 39223)\n",
      "(1011,)\n",
      "(1011, 19825)\n",
      "(786, 39223)\n",
      "(786,)\n",
      "(674, 19825)\n",
      "(674,)\n"
     ]
    }
   ],
   "source": [
    "print(newsA_y_train.shape)\n",
    "print(newsA_X_train.shape)\n",
    "print(newsB_y_train.shape)\n",
    "print(newsB_X_train.shape)\n",
    "\n",
    "print(newsA_X_test.shape)\n",
    "print(newsA_y_test.shape)\n",
    "print(newsB_X_test.shape)\n",
    "print(newsB_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1181,)\n",
      "(1011,)\n",
      "(1011,)\n"
     ]
    }
   ],
   "source": [
    "#print(np.argsort(newsA_y_train))\n",
    "orderA = np.argsort(newsA_y_train)\n",
    "newsA_X_train = newsA_X_train[orderA]\n",
    "newsA_y_train = newsA_y_train[orderA]\n",
    "print(newsA_y_train.shape)\n",
    "\n",
    "orderB = np.argsort(newsB_y_train)\n",
    "newsB_X_train = newsB_X_train[orderB]\n",
    "newsB_y_train = newsB_y_train[orderB]\n",
    "print(newsB_y_train.shape)\n",
    "\n",
    "# cut off the extras so both views same size\n",
    "newsA_X_train = newsA_X_train[:min(len(newsA_y_train),len(newsB_y_train))]\n",
    "newsA_y_train = newsA_y_train[:min(len(newsA_y_train),len(newsB_y_train))]\n",
    "\n",
    "print(newsA_y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])\n"
     ]
    }
   ],
   "source": [
    "print((newsA_train.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1]\n",
      "(16, 39223)\n",
      "(995, 39223)\n"
     ]
    }
   ],
   "source": [
    "# split into labeled and unlabeled\n",
    "Lsize = 12\n",
    "\n",
    "np.random.seed(8)\n",
    "mask = np.random.choice([False, True], (newsA_X_train.shape[0]), p=[((newsA_X_train.shape[0]) - Lsize)/(newsA_X_train.shape[0]), Lsize/(newsA_X_train.shape[0])])\n",
    "\n",
    "\n",
    "newsA_X_train_L = newsA_X_train[mask,:]\n",
    "newsA_y_train_L = newsA_y_train[mask]\n",
    "newsA_X_train_U = newsA_X_train[mask==False,:]\n",
    "\n",
    "newsB_X_train_L = newsB_X_train[mask,:]\n",
    "newsB_y_train_L = newsB_y_train[mask]\n",
    "newsB_X_train_U = newsB_X_train[mask==False,:]\n",
    "\n",
    "print(newsA_y_train_L)\n",
    "print(newsA_X_train_L.shape)\n",
    "print(newsA_X_train_U.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "class MVCoTrain:\n",
    "    \n",
    "    def __init__(self, model_type=\"Naive_Bayes\"):\n",
    "        if model_type == \"Naive_Bayes\":\n",
    "            self.h1 = GaussianNB()\n",
    "            self.h2 = GaussianNB()\n",
    "        else:\n",
    "            raise Exception(\"Bad model_type\")\n",
    "        self.model_type = model_type\n",
    "        \n",
    "    # return the most confident row indices for positive and negative\n",
    "    def pred_self(self, modelnum, Z_X_UU, n, p):\n",
    "        if modelnum==\"h1\":\n",
    "            probs = self.h1.predict_proba(Z_X_UU)\n",
    "            y_pred = self.h1.predict(Z_X_UU)\n",
    "        elif modelnum==\"h2\":\n",
    "            probs = self.h2.predict_proba(Z_X_UU)\n",
    "            y_pred = self.h2.predict(Z_X_UU)\n",
    "                    \n",
    "        probs_class0 = probs[:,0]\n",
    "        probs_class1 = probs[:,1]\n",
    "        topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "        print(\"bad labels\")\n",
    "        print(y_pred[topN_class0]==1)\n",
    "        print(topN_class0)\n",
    "        topN_class0 = np.delete(topN_class0, y_pred[topN_class0]==1)\n",
    "        print(\"after delete\")\n",
    "        print(topN_class0)\n",
    "        topN_pred0 = y_pred[topN_class0]\n",
    "#         print(\" hhhh \")\n",
    "#         print(y_pred)\n",
    "#         print(probs)\n",
    "        \n",
    "#         print(\"here\")\n",
    "#         print(probs_class0[topN_class0])\n",
    "#         print(topN_pred0)\n",
    "        topP_class1 = np.argsort(probs_class1)[-p:]\n",
    "        print(\"bad labels P\")\n",
    "        print(y_pred[topP_class1]==0)\n",
    "        print(\"BEFORE DELETE\")\n",
    "        print(topP_class1)\n",
    "        topP_class1 = np.delete(topP_class1, y_pred[topP_class1]==0)\n",
    "        print(\"aFTER DELETE\")\n",
    "        print(topP_class1)\n",
    "        topP_pred1 = y_pred[topP_class1]\n",
    "        print([topN_class0])\n",
    "        print([topP_class1])\n",
    "#         print(probs_class1[topP_class1])\n",
    "#         print(topP_pred1)\n",
    "        best_locs = np.transpose(np.hstack([topN_class0, topP_class1]))\n",
    "        preds = np.transpose(np.hstack([topN_pred0, topP_pred1]))\n",
    "        if len(set(best_locs)) is not len(best_locs):\n",
    "            print(\"Error\")\n",
    "            raise Exception\n",
    "#         print(best_locs)\n",
    "#         print(preds)\n",
    "        return (best_locs, preds)\n",
    "\n",
    "    # replenish UU subset with examples from U set\n",
    "    def replenish(self, A_X_UU, A_X_U, B_X_UU, B_X_U, num_removed):\n",
    "        # not enough examples left to fully replenish and have leftover\n",
    "        if num_removed >= len(A_X_U):\n",
    "            A_X_UU = np.vstack((A_X_UU, A_X_U))\n",
    "            B_X_UU = np.vstack((B_X_UU, B_X_U))\n",
    "            return (A_X_UU, np.array([]), B_X_UU, np.array([]))\n",
    "        \n",
    "        # choose a random sample of the examples in the unlabeled set U\n",
    "        # to put into the UU subset\n",
    "        random.seed(11)\n",
    "        selector = np.arange(0,len(A_X_U))\n",
    "        random.shuffle(selector)\n",
    "        selector = selector[:num_removed]\n",
    "        print(selector)\n",
    "        A_X_UU = np.vstack((A_X_UU, A_X_U[selector,:]))\n",
    "        B_X_UU = np.vstack((B_X_UU, B_X_U[selector,:]))\n",
    "        # delete these from the unlabeled set U\n",
    "        A_X_U = np.delete(A_X_U, selector, axis=0)\n",
    "        B_X_U = np.delete(B_X_U, selector, axis=0)\n",
    "        return (A_X_UU, A_X_U, B_X_UU, B_X_U)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def fit_full(self, A_X_L, A_y_L, B_X_L, B_y_L, A_X_U, B_X_U, n=10, p=10, max_iters=20, seed=10):\n",
    "        # randomly get subgroup of the unlabeled data\n",
    "        UUsize = 4 * n + 4 * p\n",
    "        np.random.seed(seed)\n",
    "        mask = np.random.choice([False, True], (A_X_U.shape[0]), p=[((A_X_U.shape[0]) - UUsize)/(A_X_U.shape[0]), UUsize/(A_X_U.shape[0])])\n",
    "        notMask = np.invert(mask)\n",
    "#         print(notMask[:100])\n",
    "#         print(mask[:100])\n",
    "        notMask = np.flatnonzero(notMask)\n",
    "        mask = np.flatnonzero(mask)\n",
    "#         print(mask)\n",
    "#         print(len(mask))\n",
    "#         print(len(notMask))\n",
    "#         print(A_X_U.shape)\n",
    "        A_X_UU = A_X_U[mask,:]\n",
    "        B_X_UU = B_X_U[mask,:]\n",
    "        A_X_U = A_X_U[notMask,:]\n",
    "        B_X_U = B_X_U[notMask,:]\n",
    "#         print(A_X_U.shape)\n",
    "#         print(A_X_UU.shape)\n",
    "        \n",
    "        \n",
    "        A_X_L = A_X_L.toarray()\n",
    "        B_X_L = B_X_L.toarray()\n",
    "        A_X_U = A_X_U.toarray()\n",
    "        B_X_U = B_X_U.toarray()\n",
    "        A_X_UU = A_X_UU.toarray()\n",
    "        B_X_UU = B_X_UU.toarray()\n",
    "           \n",
    "        # iterate and fit\n",
    "        for n_iter in range(2):\n",
    "            print(\"iter \" + str(n_iter))\n",
    "            # fit h1 on the labeled data A_X_L\n",
    "            self.h1.fit(A_X_L, A_y_L)\n",
    "            \n",
    "            # fit h2 on labeled data B_X_L\n",
    "            self.h2.fit(B_X_L, B_y_L)\n",
    "            \n",
    "            # get h1 predictions of A_X_UU\n",
    "            best_rows1, best_preds1 = self.pred_self(\"h1\", A_X_UU, n, p)\n",
    "            print(best_rows1.shape)\n",
    "                    \n",
    "            # get the h2 predictions of B_X_UU\n",
    "            best_rows2, best_preds2 = self.pred_self(\"h2\", B_X_UU, n, p)\n",
    "            print(best_rows2.shape)\n",
    "            \n",
    "            # union these and put these best predictions into B_X_L, then replenish both UU\n",
    "            best_rows = np.array(list(set(np.hstack([best_rows1, best_rows2]))))\n",
    "            print(best_rows.shape)\n",
    "            num_removed = len(best_rows)\n",
    "            \n",
    "            y_L_new = np.zeros_like(best_rows)\n",
    "            remove_mask = np.zeros_like(best_rows)\n",
    "            for i,row in enumerate(best_rows):\n",
    "                remove_mask[i] = row\n",
    "                if row in best_rows1:\n",
    "                    print(\"best row\")\n",
    "                    print(row)\n",
    "                    print(best_rows1)\n",
    "                    print(np.where(best_rows1==row))\n",
    "                    y_L_new[i] = best_preds1[np.where(best_rows1==row)]\n",
    "                else:\n",
    "                    y_L_new[i] = best_preds2[np.where(best_rows2==row)]\n",
    "                    \n",
    "            \n",
    "            print(y_L_new)\n",
    "            \n",
    "            # add to labeled sets\n",
    "            print(A_X_L.shape)\n",
    "            print(A_X_UU[best_rows,:].shape)\n",
    "            \n",
    "            A_X_L = np.vstack((A_X_L, A_X_UU[best_rows,:]))\n",
    "            print(A_X_L.shape)\n",
    "            B_X_L = np.vstack((B_X_L, B_X_UU[best_rows,:]))\n",
    "            \n",
    "            # Add labels########################\n",
    "#             print(\"size\")\n",
    "#             print(y_L_new.shape)\n",
    "#             print(A_y_L.shape)\n",
    "#             print(B_y_L.shape)\n",
    "            A_y_L = np.transpose(np.hstack((A_y_L, y_L_new)))\n",
    "            B_y_L = np.transpose(np.hstack((B_y_L, y_L_new)))\n",
    "#             print(A_y_L.shape)\n",
    "#             print(B_y_L.shape)\n",
    "            \n",
    "            # remove from unlabeled set\n",
    "            mask = np.ones((A_X_UU.shape[0],))\n",
    "            mask[remove_mask] = 0\n",
    "            print(\"UU shape\")\n",
    "            print(A_X_UU.shape)\n",
    "            print(B_X_UU.shape)\n",
    "            A_X_UU = A_X_UU[mask==1,:]\n",
    "            B_X_UU = B_X_UU[mask==1,:]\n",
    "            print(A_X_UU.shape)\n",
    "            print(B_X_UU.shape)\n",
    "            \n",
    "            # replenish UU sets\n",
    "            print(\"num removed\")\n",
    "            print(num_removed)\n",
    "            print(\"before replenish\")\n",
    "            print(A_X_U.shape)\n",
    "            print(A_X_UU.shape)\n",
    "            (A_X_UU, A_X_U, B_X_UU, B_X_U) = self.replenish(A_X_UU, A_X_U, B_X_UU, B_X_U, num_removed)\n",
    "            print(\"shape after replenish\")\n",
    "            print(A_X_U.shape)\n",
    "            print(A_X_UU.shape)\n",
    "            \n",
    "            print(\"new shapes\")\n",
    "            print(A_X_L.shape)\n",
    "            print(A_y_L.shape)\n",
    "            print(B_X_L.shape)\n",
    "            print(B_y_L.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,2,3,4,5,5,5,5,5,6])\n",
    "y = np.array(list(set(x)))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "bad labels\n",
      "[False False False False False False False False False False]\n",
      "[30  5 20 28 27 44 45 12 29 17]\n",
      "after delete\n",
      "[ 5 20 28 27 44 45 12 29 17]\n",
      "bad labels P\n",
      "[False False False False False False False False False False]\n",
      "BEFORE DELETE\n",
      "[26 31 33 34 35 71 37 38 19 72]\n",
      "aFTER DELETE\n",
      "[31 33 34 35 71 37 38 19 72]\n",
      "[array([ 5, 20, 28, 27, 44, 45, 12, 29, 17], dtype=int64)]\n",
      "[array([31, 33, 34, 35, 71, 37, 38, 19, 72], dtype=int64)]\n",
      "(18,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gavin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integer\n",
      "C:\\Users\\gavin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: FutureWarning: in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad labels\n",
      "[False False False False False False False False False False]\n",
      "[17 20 22 27 31 32 38 45 53 72]\n",
      "after delete\n",
      "[20 22 27 31 32 38 45 53 72]\n",
      "bad labels P\n",
      "[False False False False False False False False False False]\n",
      "BEFORE DELETE\n",
      "[35 71 37 39 40 41 42 43  8 36]\n",
      "aFTER DELETE\n",
      "[71 37 39 40 41 42 43  8 36]\n",
      "[array([20, 22, 27, 31, 32, 38, 45, 53, 72], dtype=int64)]\n",
      "[array([71, 37, 39, 40, 41, 42, 43,  8, 36], dtype=int64)]\n",
      "(18,)\n",
      "(28,)\n",
      "best row\n",
      "5\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([0], dtype=int64),)\n",
      "best row\n",
      "12\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([6], dtype=int64),)\n",
      "best row\n",
      "17\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([8], dtype=int64),)\n",
      "best row\n",
      "19\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([16], dtype=int64),)\n",
      "best row\n",
      "20\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([1], dtype=int64),)\n",
      "best row\n",
      "27\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([3], dtype=int64),)\n",
      "best row\n",
      "28\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([2], dtype=int64),)\n",
      "best row\n",
      "29\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([7], dtype=int64),)\n",
      "best row\n",
      "31\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([9], dtype=int64),)\n",
      "best row\n",
      "33\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([10], dtype=int64),)\n",
      "best row\n",
      "34\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([11], dtype=int64),)\n",
      "best row\n",
      "35\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([12], dtype=int64),)\n",
      "best row\n",
      "37\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([14], dtype=int64),)\n",
      "best row\n",
      "38\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([15], dtype=int64),)\n",
      "best row\n",
      "44\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([4], dtype=int64),)\n",
      "best row\n",
      "45\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([5], dtype=int64),)\n",
      "best row\n",
      "71\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([13], dtype=int64),)\n",
      "best row\n",
      "72\n",
      "[ 5 20 28 27 44 45 12 29 17 31 33 34 35 71 37 38 19 72]\n",
      "(array([17], dtype=int64),)\n",
      "[0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1]\n",
      "(16, 39223)\n",
      "(28, 39223)\n",
      "(44, 39223)\n",
      "UU shape\n",
      "(73, 39223)\n",
      "(73, 19825)\n",
      "(45, 39223)\n",
      "(45, 19825)\n",
      "num removed\n",
      "28\n",
      "before replenish\n",
      "(922, 39223)\n",
      "(45, 39223)\n",
      "[581 306 361  51  83  57 608 668 449 279 280  78 337 188 227 571 142 645\n",
      " 747 550 166 453 528 411 549 435 292 368]\n",
      "shape after replenish\n",
      "(894, 39223)\n",
      "(73, 39223)\n",
      "new shapes\n",
      "(44, 39223)\n",
      "(44,)\n",
      "(44, 19825)\n",
      "(44,)\n",
      "iter 1\n",
      "bad labels\n",
      "[ True  True  True False False False False False False False]\n",
      "[26 27 28 37 17 58 20 54 59 53]\n",
      "after delete\n",
      "[28 37 17 58 20 54 59 53]\n",
      "bad labels P\n",
      "[False False False False False False False False False False]\n",
      "BEFORE DELETE\n",
      "[18 28 26 25 24 23 22 21 27 72]\n",
      "aFTER DELETE\n",
      "[28 26 25 24 23 22 21 27 72]\n",
      "[array([28, 37, 17, 58, 20, 54, 59, 53], dtype=int64)]\n",
      "[array([28, 26, 25, 24, 23, 22, 21, 27, 72], dtype=int64)]\n",
      "Error\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-8f368c8e1485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMVtest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMVCoTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mMVtest1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewsA_X_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsA_y_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsB_X_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsB_y_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsA_X_train_U\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsB_X_train_U\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-160-c76d13faa0b1>\u001b[0m in \u001b[0;36mfit_full\u001b[1;34m(self, A_X_L, A_y_L, B_X_L, B_y_L, A_X_U, B_X_U, n, p, max_iters, seed)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;31m# get h1 predictions of A_X_UU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mbest_rows1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_preds1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_X_UU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_rows1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-160-c76d13faa0b1>\u001b[0m in \u001b[0;36mpred_self\u001b[1;34m(self, modelnum, Z_X_UU, n, p)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;31m#         print(best_locs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#         print(preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MVtest1 = MVCoTrain()\n",
    "MVtest1.fit_full(newsA_X_train_L, newsA_y_train_L, newsB_X_train_L, newsB_y_train_L, newsA_X_train_U, newsB_X_train_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from https://github.com/jjrob13/sklearn_cotraining/blob/master/sklearn_cotraining/classifiers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "class CoTrainingClassifier(object):\n",
    "    \"\"\"\n",
    "    Organization from https://github.com/jjrob13/sklearn_cotraining\n",
    "    Algorithm based on \"Combining Labeled and Unlabeled Data with Co-Training\", Blum and Mitchell, 1998 \n",
    "    \n",
    "    Parameters:\n",
    "    clf - The classifier that will be used in the cotraining algorithm on the view 1 feature set\n",
    "        (If clf2 is not specified, then the same type of classifier will be used on the second view).\n",
    "\n",
    "    clf2 - (Optional) A different classifier type can be specified to be used on the X2 feature set\n",
    "         if desired.\n",
    "\n",
    "    p - (Optional) The number of positive examples that will be 'labeled' by each classifier during each iteration\n",
    "        The default is the is determined by the smallest integer ratio of positive to negative samples in L (from paper)\n",
    "\n",
    "    n - (Optional) The number of negative examples that will be 'labeled' by each classifier during each iteration\n",
    "    The default is the is determined by the smallest integer ratio of positive to negative samples in L (from paper)\n",
    "\n",
    "    k - (Optional) The number of iterations\n",
    "        The default is 30 (from paper)\n",
    "\n",
    "    u - (Optional) The size of the pool of unlabeled samples from which the classifier can choose\n",
    "    Default - 75 (from paper)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clf, clf2=None, p=-1, n=-1, k=30, u=75):\n",
    "        \n",
    "        self.clf1_ = clf\n",
    "\n",
    "        if clf2 == None:\n",
    "            self.clf2_ = copy.copy(clf)\n",
    "        else:\n",
    "            self.clf2_ = clf2\n",
    "\n",
    "        #if user only specifies one of n or p, raise an exception\n",
    "        if (p == -1 and n != -1) or (p != -1 and n == -1):\n",
    "            raise ValueError('Must supply either both p and n, or neither')\n",
    "\n",
    "        self.p_ = p\n",
    "        self.n_ = n\n",
    "        self.k_ = k\n",
    "        self.u_ = u\n",
    "\n",
    "        random.seed(10)\n",
    "        \n",
    "        # for testing\n",
    "        self.partial_error_ = []\n",
    "\n",
    "\n",
    "    def fit(self, X1, X2, y, X1_test=None, X2_test=None, y_test=None):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        fits the classifiers on the partially labeled data, y.\n",
    "\n",
    "        Parameters:\n",
    "        X1 - array-like (n_samples, n_features_1): first set of features for samples\n",
    "        X2 - array-like (n_samples, n_features_2): second set of features for samples\n",
    "        y - array-like (n_samples): labels for samples, -1 indicates unlabeled\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # convert to numpy array\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        #set the n and p parameters if we need to\n",
    "        if self.p_ == -1 and self.n_ == -1:\n",
    "            num_pos = sum(1 for y_i in y if y_i == 1)\n",
    "            num_neg = sum(1 for y_i in y if y_i == 0)\n",
    "\n",
    "            n_p_ratio = num_neg / float(num_pos)\n",
    "\n",
    "            if n_p_ratio > 1:\n",
    "                self.p_ = 1\n",
    "                self.n_ = round(self.p_*n_p_ratio)\n",
    "\n",
    "            else:\n",
    "                self.n_ = 1\n",
    "                self.p_ = round(self.n_/n_p_ratio)\n",
    "        print(self.n_)\n",
    "        print(self.p_)\n",
    "\n",
    "        assert(self.p_ > 0 and self.n_ > 0 and self.k_ > 0 and self.u_ > 0)\n",
    "\n",
    "        #the set of unlabeled samples\n",
    "        U = [i for i, y_i in enumerate(y) if y_i == -1]\n",
    "\n",
    "        #we randomize here, and then just take from the back so we don't have to sample every time\n",
    "        random.shuffle(U)\n",
    "\n",
    "        #this is U' in paper\n",
    "        U_ = U[-min(len(U), self.u_):]\n",
    "\n",
    "        #the samples that are initially labeled\n",
    "        L = [i for i, y_i in enumerate(y) if y_i != -1]\n",
    "\n",
    "        #remove the samples in U_ from U\n",
    "        U = U[:-len(U_)]\n",
    "\n",
    "\n",
    "        it = 0 #number of cotraining iterations we've done so far\n",
    "\n",
    "        #loop until we have assigned labels to everything in U or we hit our iteration break condition\n",
    "        while it != self.k_ and U:\n",
    "            it += 1\n",
    "\n",
    "            self.clf1_.fit(X1[L], y[L])\n",
    "            self.clf2_.fit(X2[L], y[L])\n",
    "\n",
    "            y1_prob = self.clf1_.predict_proba(X1[U_])\n",
    "            y2_prob = self.clf2_.predict_proba(X2[U_])\n",
    "\n",
    "            n, p = [], []\n",
    "            \n",
    "            for i in (y1_prob[:,0].argsort())[-self.n_:]:\n",
    "                #if y1_prob[i,0] > 0.5:\n",
    "                n.append(i)\n",
    "            for i in (y1_prob[:,1].argsort())[-self.p_:]:\n",
    "                #if y1_prob[i,1] > 0.5:\n",
    "                p.append(i)\n",
    "\n",
    "            for i in (y2_prob[:,0].argsort())[-self.n_:]:\n",
    "                #if y2_prob[i,0] > 0.5:\n",
    "                n.append(i)\n",
    "            for i in (y2_prob[:,1].argsort())[-self.p_:]:\n",
    "                #if y2_prob[i,1] > 0.5:\n",
    "                p.append(i)\n",
    "\n",
    "            #label the samples and remove the newly added samples from U_\n",
    "            y[[U_[x] for x in p]] = 1\n",
    "            y[[U_[x] for x in n]] = 0\n",
    "\n",
    "            L.extend([U_[x] for x in p])\n",
    "            L.extend([U_[x] for x in n])\n",
    "\n",
    "            U_ = [elem for elem in U_ if not (elem in p or elem in n)]\n",
    "\n",
    "            #add new elements to U_\n",
    "            add_counter = 0 #number we have added from U to U_\n",
    "            num_to_add = len(p) + len(n)\n",
    "            while add_counter != num_to_add and U:\n",
    "                add_counter += 1\n",
    "                U_.append(U.pop())\n",
    "                \n",
    "            \n",
    "            # if input testing data as well, find the incrememtal update on accuracy\n",
    "            if X1_test is not None and X2_test is not None and y_test is not None:\n",
    "                y_pred = self.predict(X1_test, X2_test)\n",
    "                self.partial_error_.append(1-accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "            #TODO: Handle the case where the classifiers fail to agree on any of the samples (i.e. both n and p are empty)\n",
    "\n",
    "\n",
    "        #fit the final model\n",
    "        self.clf1_.fit(X1[L], y[L])\n",
    "        self.clf2_.fit(X2[L], y[L])\n",
    "        \n",
    "        return self.partial_error_\n",
    "\n",
    "\n",
    "    #TODO: Move this outside of the class into a util file.\n",
    "    def supports_proba(self, clf, x):\n",
    "        \"\"\"Checks if a given classifier supports the 'predict_proba' method, given a single vector x\"\"\"\n",
    "        try:\n",
    "            clf.predict_proba([x])\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def predict(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Predict the classes of the samples represented by the features in X1 and X2.\n",
    "\n",
    "        Parameters:\n",
    "        X1 - array-like (n_samples, n_features1)\n",
    "        X2 - array-like (n_samples, n_features2)\n",
    "\n",
    "        \n",
    "        Output:\n",
    "        y - array-like (n_samples)\n",
    "            These are the predicted classes of each of the samples.  If the two classifiers, don't agree, we try\n",
    "            to use predict_proba and take the classifier with the highest confidence and if predict_proba is not implemented, then we randomly\n",
    "            assign either 0 or 1.  We hope to improve this in future releases.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        y1 = self.clf1_.predict(X1)\n",
    "        y2 = self.clf2_.predict(X2)\n",
    "\n",
    "        proba_supported = self.supports_proba(self.clf1_, X1[0]) and self.supports_proba(self.clf2_, X2[0])\n",
    "\n",
    "        #fill y_pred with -1 so we can identify the samples in which the classifiers failed to agree\n",
    "        y_pred = np.asarray([-1] * X1.shape[0])\n",
    "        num_disagree = 0\n",
    "        num_agree = 0\n",
    "\n",
    "        for i, (y1_i, y2_i) in enumerate(zip(y1, y2)):\n",
    "            if y1_i == y2_i:\n",
    "                y_pred[i] = y1_i\n",
    "                num_agree += 1\n",
    "            elif proba_supported:\n",
    "                y1_probs = self.clf1_.predict_proba([X1[i]])[0]\n",
    "                y2_probs = self.clf2_.predict_proba([X2[i]])[0]\n",
    "                sum_y_probs = [prob1 + prob2 for (prob1, prob2) in zip(y1_probs, y2_probs)]\n",
    "                max_sum_prob = max(sum_y_probs)\n",
    "                y_pred[i] = sum_y_probs.index(max_sum_prob)\n",
    "                num_disagree += 1\n",
    "            else:\n",
    "                #the classifiers disagree and don't support probability, so we guess\n",
    "                y_pred[i] = random.randint(0, 1)\n",
    "                \n",
    "        print(\"agree\")\n",
    "        print(num_agree)\n",
    "        print(\"disagree\")\n",
    "        print(num_disagree)\n",
    "\n",
    "\n",
    "        #check that we did everything right\n",
    "        assert not (-1 in y_pred)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def predict_proba(self, X1, X2):\n",
    "        \"\"\"Predict the probability of the samples belonging to each class.\"\"\"\n",
    "        y_proba = np.full((X1.shape[0], 2), -1)\n",
    "\n",
    "        y1_proba = self.clf1_.predict_proba(X1)\n",
    "        y2_proba = self.clf2_.predict_proba(X2)\n",
    "\n",
    "        for i, (y1_i_dist, y2_i_dist) in enumerate(zip(y1_proba, y2_proba)):\n",
    "            y_proba[i][0] = (y1_i_dist[0] + y2_i_dist[0]) / 2\n",
    "            y_proba[i][1] = (y1_i_dist[1] + y2_i_dist[1]) / 2\n",
    "\n",
    "        _epsilon = 0.0001\n",
    "        assert all(abs(sum(y_dist) - 1) <= _epsilon for y_dist in y_proba)\n",
    "        return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "setA = ['comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware']\n",
    "setB = ['talk.politics.misc','talk.politics.guns']\n",
    "\n",
    "newsA_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=setA)\n",
    "newsB_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=setB)\n",
    "\n",
    "newsA_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=setA)\n",
    "newsB_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=setB)\n",
    "\n",
    "newsA_y_train = newsA_train.target\n",
    "newsB_y_train = newsB_train.target\n",
    "\n",
    "newsA_y_test = newsA_test.target\n",
    "newsB_y_test = newsB_test.target\n",
    "\n",
    "vectorizerA = TfidfVectorizer()\n",
    "newsA_X_train = vectorizerA.fit_transform(newsA_train.data)\n",
    "newsA_X_test = vectorizerA.transform(newsA_test.data)\n",
    "\n",
    "#vectorizerB = TfidfVectorizer()\n",
    "# newsB_X_train = vectorizerB.fit_transform(newsB_train.data)\n",
    "# newsB_X_test = vectorizerB.transform(newsB_test.data)\n",
    "newsB_X_train = vectorizerA.transform(newsB_train.data)\n",
    "newsB_X_test = vectorizerA.transform(newsB_test.data)\n",
    "\n",
    "\n",
    "print(newsA_y_train.shape)\n",
    "print(newsA_X_train.shape)\n",
    "print(newsB_y_train.shape)\n",
    "print(newsB_X_train.shape)\n",
    "\n",
    "print(newsA_X_test.shape)\n",
    "print(newsA_y_test.shape)\n",
    "print(newsB_X_test.shape)\n",
    "print(newsB_y_test.shape)\n",
    "\n",
    "#make numpy arrays\n",
    "\n",
    "newsA_X_train = newsA_X_train.toarray()\n",
    "newsB_X_train = newsB_X_train.toarray()\n",
    "\n",
    "newsA_X_test = newsA_X_test.toarray()\n",
    "newsB_X_test = newsB_X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 1 1 1 1 1 1]\n",
      "465\n",
      "546\n",
      "(1009, 39223)\n",
      "(1009,)\n",
      "(1009, 39223)\n",
      "(1009,)\n",
      "310\n",
      "364\n",
      "(672, 39223)\n",
      "(672,)\n",
      "(672, 39223)\n",
      "(672,)\n",
      "[0 0 0 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# make same size\n",
    "\n",
    "newsA_X_train_old = newsA_X_train.copy()\n",
    "\n",
    "order_train = np.argsort(newsA_y_train)\n",
    "newsA_y_train = newsA_y_train[order_train]\n",
    "newsA_X_train = newsA_X_train[order_train]\n",
    "\n",
    "order_train = np.argsort(newsB_y_train)\n",
    "newsB_y_train = newsB_y_train[order_train]\n",
    "newsB_X_train = newsB_X_train[order_train]\n",
    "\n",
    "\n",
    "class1len = min((len(np.argwhere(newsA_y_train==1)), len(np.argwhere(newsB_y_train==1))))\n",
    "class0len = min((len(np.argwhere(newsA_y_train==0)), len(np.argwhere(newsB_y_train==0))))\n",
    "\n",
    "\n",
    "newsA_y_train = np.concatenate((newsA_y_train[:class0len-1], newsA_y_train[-(class1len)+1:]))\n",
    "newsA_X_train = np.vstack((newsA_X_train[:class0len-1], newsA_X_train[-(class1len)+1:]))\n",
    "\n",
    "newsB_y_train = np.concatenate((newsB_y_train[:class0len-1], newsB_y_train[-(class1len)+1:]))\n",
    "newsB_X_train = np.vstack((newsB_X_train[:class0len-1], newsB_X_train[-(class1len)+1:]))\n",
    "\n",
    "print(newsA_y_train[np.arange(540,551)])\n",
    "print(newsB_y_train[np.arange(540,551)])\n",
    "\n",
    "print(class1len)\n",
    "print(class0len)\n",
    "\n",
    "print(newsA_X_train.shape)\n",
    "print(newsA_y_train.shape)\n",
    "print(newsB_X_train.shape)\n",
    "print(newsB_y_train.shape)\n",
    "\n",
    "# reshape test data\n",
    "order_test = np.argsort(newsA_y_test)\n",
    "newsA_y_test = newsA_y_test[order_test]\n",
    "newsA_X_test = newsA_X_test[order_test]\n",
    "\n",
    "order_test = np.argsort(newsB_y_test)\n",
    "newsB_y_test = newsB_y_test[order_test]\n",
    "newsB_X_test = newsB_X_test[order_test]\n",
    "\n",
    "\n",
    "class1len = min((len(np.argwhere(newsA_y_test==1)), len(np.argwhere(newsB_y_test==1))))\n",
    "class0len = min((len(np.argwhere(newsA_y_test==0)), len(np.argwhere(newsB_y_test==0))))\n",
    "\n",
    "\n",
    "newsA_y_test = np.concatenate((newsA_y_test[:class0len-1], newsA_y_test[-(class1len)+1:]))\n",
    "newsA_X_test = np.vstack((newsA_X_test[:class0len-1], newsA_X_test[-(class1len)+1:]))\n",
    "\n",
    "newsB_y_test = np.concatenate((newsB_y_test[:class0len-1], newsB_y_test[-(class1len)+1:]))\n",
    "newsB_X_test = np.vstack((newsB_X_test[:class0len-1], newsB_X_test[-(class1len)+1:]))\n",
    "\n",
    "print(class1len)\n",
    "print(class0len)\n",
    "\n",
    "print(newsA_X_test.shape)\n",
    "print(newsA_y_test.shape)\n",
    "print(newsB_X_test.shape)\n",
    "print(newsB_y_test.shape)\n",
    "\n",
    "\n",
    "print(newsA_y_test[np.arange(360,371)])\n",
    "print(newsB_y_test[np.arange(360,371)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly pick some labels to set to -1\n",
    "Lsize = 80\n",
    "labels = newsA_y_train.copy()\n",
    "minus1 = np.arange(0,len(labels))\n",
    "random.seed(11)\n",
    "random.shuffle(minus1)\n",
    "minus1 = minus1[:-Lsize]\n",
    "labels[minus1] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4]\n",
      " [ 15]\n",
      " [ 30]\n",
      " [ 36]\n",
      " [ 42]\n",
      " [ 60]\n",
      " [ 64]\n",
      " [ 85]\n",
      " [ 87]\n",
      " [ 92]\n",
      " [ 96]\n",
      " [145]\n",
      " [161]\n",
      " [189]\n",
      " [190]\n",
      " [194]\n",
      " [200]\n",
      " [235]\n",
      " [239]\n",
      " [247]\n",
      " [260]\n",
      " [284]\n",
      " [295]\n",
      " [301]\n",
      " [310]\n",
      " [322]\n",
      " [334]\n",
      " [405]\n",
      " [416]\n",
      " [451]\n",
      " [457]\n",
      " [462]\n",
      " [463]\n",
      " [468]\n",
      " [475]\n",
      " [476]\n",
      " [487]\n",
      " [511]\n",
      " [520]\n",
      " [524]\n",
      " [525]\n",
      " [531]\n",
      " [541]]\n",
      "(1009,)\n"
     ]
    }
   ],
   "source": [
    "print(np.argwhere(labels == 0))\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "agree\n",
      "379\n",
      "disagree\n",
      "293\n",
      "agree\n",
      "380\n",
      "disagree\n",
      "292\n",
      "agree\n",
      "363\n",
      "disagree\n",
      "309\n",
      "agree\n",
      "354\n",
      "disagree\n",
      "318\n",
      "agree\n",
      "360\n",
      "disagree\n",
      "312\n",
      "agree\n",
      "356\n",
      "disagree\n",
      "316\n",
      "agree\n",
      "355\n",
      "disagree\n",
      "317\n",
      "agree\n",
      "346\n",
      "disagree\n",
      "326\n",
      "agree\n",
      "367\n",
      "disagree\n",
      "305\n",
      "agree\n",
      "372\n",
      "disagree\n",
      "300\n",
      "agree\n",
      "368\n",
      "disagree\n",
      "304\n",
      "agree\n",
      "369\n",
      "disagree\n",
      "303\n",
      "agree\n",
      "366\n",
      "disagree\n",
      "306\n",
      "agree\n",
      "363\n",
      "disagree\n",
      "309\n",
      "agree\n",
      "357\n",
      "disagree\n",
      "315\n",
      "agree\n",
      "361\n",
      "disagree\n",
      "311\n",
      "agree\n",
      "358\n",
      "disagree\n",
      "314\n",
      "agree\n",
      "361\n",
      "disagree\n",
      "311\n",
      "agree\n",
      "364\n",
      "disagree\n",
      "308\n",
      "agree\n",
      "363\n",
      "disagree\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "# Fit the training data\n",
    "gnb1 = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "clf = CoTrainingClassifier(gnb1, gnb2, k=20)\n",
    "errors = clf.fit(newsA_X_train, newsB_X_train, labels, newsA_X_test, newsB_X_test, newsA_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agree\n",
      "355\n",
      "disagree\n",
      "317\n",
      "0.623511904762\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred = clf.predict(newsA_X_test, newsB_X_test)\n",
    "print(accuracy_score(newsA_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ecf4fb438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(100*np.array(errors))\n",
    "plt.xlabel(\"Co-training iterations\")\n",
    "plt.ylabel(\"Classification Error (%)\")\n",
    "plt.savefig(\"Error Decrease 4.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50  1\n",
       "0  1   85  66  29    0  26.6  0.351  31  0\n",
       "1  8  183  64   0    0  23.3  0.672  32  1\n",
       "2  1   89  66  23   94  28.1  0.167  21  0\n",
       "3  0  137  40  35  168  43.1  2.288  33  1\n",
       "4  5  116  74   0    0  25.6  0.201  30  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"Diabetes_Dataset.csv\")\n",
    "full_labels = full_data['1']\n",
    "full_data.head()\n",
    "full_data = full_data.drop('1',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50\n",
       "0  1   85  66  29    0  26.6  0.351  31\n",
       "1  8  183  64   0    0  23.3  0.672  32\n",
       "2  1   89  66  23   94  28.1  0.167  21\n",
       "3  0  137  40  35  168  43.1  2.288  33\n",
       "4  5  116  74   0    0  25.6  0.201  30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = full_data.as_matrix()\n",
    "Y = full_labels.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into two groups (\"views\")\n",
    "Lsize = 20\n",
    "X_train_L = X_train[:Lsize,:]\n",
    "X_train_U = X_train[Lsize:,:]\n",
    "y_train_L = y_train[:Lsize]\n",
    "y_train_U = np.zeros_like(y_train[Lsize:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8)\n",
      "(670, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_L.shape)\n",
    "print(X_train_U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy iter 1 = \n",
      "0.675324675325\n",
      "(60,)\n",
      "(60,)\n",
      "Accuracy iter 2 = \n",
      "0.701298701299\n",
      "(60,)\n",
      "(60,)\n",
      "(553, 8)\n",
      "(140, 8)\n",
      "(140,)\n",
      "Accuracy iter 3 = \n",
      "0.753246753247\n",
      "(60,)\n",
      "(60,)\n",
      "(496, 8)\n",
      "(200, 8)\n",
      "(200,)\n",
      "Accuracy iter 4 = \n",
      "0.727272727273\n",
      "(60,)\n",
      "(60,)\n",
      "(441, 8)\n",
      "(260, 8)\n",
      "(260,)\n",
      "Accuracy iter 5 = \n",
      "0.701298701299\n",
      "(60,)\n",
      "(60,)\n",
      "(383, 8)\n",
      "(320, 8)\n",
      "(320,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# test fitting to a single view\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 1 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "# print(X_train_U.shape)\n",
    "\n",
    "# Iter 2\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 2 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "\n",
    "# Iter 3\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 3 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "\n",
    "# Iter 4\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 4 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "\n",
    "# Iter 5\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 5 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "class CoTrainSingleView:\n",
    "    def __init__(self):\n",
    "        gnb1 = GaussianNB()\n",
    "        \n",
    "    def fit_full(self,X_L,y_L,X_U):\n",
    "        # fit on the labeled data\n",
    "        gnb1.fit(X_L,y_L)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
