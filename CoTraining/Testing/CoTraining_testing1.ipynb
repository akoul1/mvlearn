{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Co-Training Implementation\n",
    "**Based on the Blum and Mitchell, 1998 paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setA = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "setA = ['comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware']\n",
    "setB = ['talk.politics.misc','talk.politics.guns']\n",
    "\n",
    "newsA_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=setA)\n",
    "newsB_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=setB)\n",
    "\n",
    "newsA_y_train = newsA_train.target\n",
    "newsB_y_train = newsB_train.target\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "newsA_X_train = vectorizer.fit_transform(newsA_train.data)\n",
    "newsB_X_train = vectorizer.fit_transform(newsB_train.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ..., 0 0 1]\n",
      "(1181, 39223)\n",
      "[0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0\n",
      " 1 0 0 0 1 0 0 1 1 1 1 0 1]\n",
      "(1011, 19825)\n"
     ]
    }
   ],
   "source": [
    "print(newsA_y_train.shape)\n",
    "print(newsA_X_train.shape)\n",
    "print(newsB_y_train.shape)\n",
    "print(newsB_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1181,)\n",
      "(1011,)\n",
      "(1011,)\n"
     ]
    }
   ],
   "source": [
    "#print(np.argsort(newsA_y_train))\n",
    "orderA = np.argsort(newsA_y_train)\n",
    "newsA_X_train = newsA_X_train[orderA]\n",
    "newsA_y_train = newsA_y_train[orderA]\n",
    "print(newsA_y_train.shape)\n",
    "\n",
    "orderB = np.argsort(newsB_y_train)\n",
    "newsB_X_train = newsB_X_train[orderB]\n",
    "newsB_y_train = newsB_y_train[orderB]\n",
    "print(newsB_y_train.shape)\n",
    "\n",
    "# cut off the extras so both views same size\n",
    "newsA_X_train = newsA_X_train[:min(len(newsA_y_train),len(newsB_y_train))]\n",
    "newsA_y_train = newsA_y_train[:min(len(newsA_y_train),len(newsB_y_train))]\n",
    "\n",
    "print(newsA_y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])\n"
     ]
    }
   ],
   "source": [
    "print((newsA_train.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1]\n",
      "(16, 39223)\n",
      "(995, 39223)\n"
     ]
    }
   ],
   "source": [
    "# split into labeled and unlabeled\n",
    "Lsize = 12\n",
    "\n",
    "np.random.seed(8)\n",
    "mask = np.random.choice([False, True], (newsA_X_train.shape[0]), p=[((newsA_X_train.shape[0]) - Lsize)/(newsA_X_train.shape[0]), Lsize/(newsA_X_train.shape[0])])\n",
    "\n",
    "\n",
    "newsA_X_train_L = newsA_X_train[mask,:]\n",
    "newsA_y_train_L = newsA_y_train[mask]\n",
    "newsA_X_train_U = newsA_X_train[mask==False,:]\n",
    "\n",
    "newsB_X_train_L = newsB_X_train[mask,:]\n",
    "newsB_y_train_L = newsB_y_train[mask]\n",
    "newsB_X_train_U = newsB_X_train[mask==False,:]\n",
    "\n",
    "print(newsA_y_train_L)\n",
    "print(newsA_X_train_L.shape)\n",
    "print(newsA_X_train_U.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "class MVCoTrain:\n",
    "    \n",
    "    def __init__(self, model_type=\"Naive_Bayes\"):\n",
    "        if model_type == \"Naive_Bayes\":\n",
    "            self.h1 = GaussianNB()\n",
    "            self.h2 = GaussianNB()\n",
    "        else:\n",
    "            raise Exception(\"Bad model_type\")\n",
    "        self.model_type = model_type\n",
    "        \n",
    "    # return the most confident row indices for positive and negative\n",
    "    def pred_self(self, modelnum, Z_X_UU, n, p):\n",
    "        if modelnum==\"h1\":\n",
    "            probs = self.h1.predict_proba(Z_X_UU)\n",
    "            y_pred = self.h1.predict(Z_X_UU)\n",
    "        elif modelnum==\"h2\":\n",
    "            probs = self.h2.predict_proba(Z_X_UU)\n",
    "            y_pred = self.h2.predict(Z_X_UU)\n",
    "                    \n",
    "        probs_class0 = probs[:,0]\n",
    "        probs_class1 = probs[:,1]\n",
    "        topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "        topN_pred0 = y_pred[topN_class0]\n",
    "#         print(\" hhhh \")\n",
    "#         print(y_pred)\n",
    "#         print(probs)\n",
    "        \n",
    "#         print(\"here\")\n",
    "#         print(probs_class0[topN_class0])\n",
    "#         print(topN_pred0)\n",
    "        topP_class1 = np.argsort(probs_class1)[-p:]\n",
    "        topP_pred1 = y_pred[topP_class1]\n",
    "#         print(probs_class1[topP_class1])\n",
    "#         print(topP_pred1)\n",
    "        best_locs = np.transpose(np.hstack([topN_class0, topP_class1]))\n",
    "        preds = np.transpose(np.hstack([topN_pred0, topP_pred1]))\n",
    "#         print(best_locs)\n",
    "#         print(preds)\n",
    "        return (best_locs, preds)\n",
    "    \n",
    "    \n",
    "    def fit_full(self, A_X_L, A_y_L, B_X_L, B_y_L, A_X_U, B_X_U, n=30, p=30, max_iters=20, seed=10):\n",
    "        # randomly get subgroup of the unlabeled data\n",
    "        UUsize = 4 * n + 4 * p\n",
    "        np.random.seed(seed)\n",
    "        mask = np.random.choice([False, True], (A_X_U.shape[0]), p=[((A_X_U.shape[0]) - UUsize)/(A_X_U.shape[0]), UUsize/(A_X_U.shape[0])])\n",
    "        print(mask[:100])\n",
    "        mask = np.flatnonzero(mask)\n",
    "        print(mask)\n",
    "        A_X_UU = A_X_U[mask,:]\n",
    "        B_X_UU = B_X_U[mask,:]\n",
    "        A_X_U = A_X_U[mask,:]\n",
    "        B_X_U = B_X_U[mask,:]\n",
    "        \n",
    "        \n",
    "        A_X_L = A_X_L.toarray()\n",
    "        B_X_L = B_X_L.toarray()\n",
    "        A_X_U = A_X_U.toarray()\n",
    "        B_X_U = B_X_U.toarray()\n",
    "        A_X_UU = A_X_UU.toarray()\n",
    "        B_X_UU = B_X_UU.toarray()\n",
    "           \n",
    "        # iterate and fit\n",
    "        for n_iter in range(2):\n",
    "            # fit h1 on the labeled data A_X_L\n",
    "            self.h1.fit(A_X_L, A_y_L)\n",
    "            \n",
    "            # fit h2 on labeled data B_X_L\n",
    "            self.h2.fit(B_X_L, B_y_L)\n",
    "            \n",
    "            # get h1 predictions of A_X_UU\n",
    "            best_rows1, best_preds1 = self.pred_self(\"h1\", A_X_UU, n, p)\n",
    "            print(best_rows1.shape)\n",
    "                    \n",
    "            # get the h2 predictions of B_X_UU\n",
    "            best_rows2, best_preds2 = self.pred_self(\"h2\", B_X_UU, n, p)\n",
    "            print(best_rows2.shape)\n",
    "            \n",
    "            # union these and put these best predictions into B_X_L, then replenish both UU\n",
    "            best_rows = np.array(list(set(np.hstack([best_rows1, best_rows2]))))\n",
    "            print(best_rows.shape)\n",
    "            \n",
    "            y_L_new = np.zeros_like(best_rows)\n",
    "            remove_mask = np.zeros_like(best_rows)\n",
    "            for i,row in enumerate(best_rows):\n",
    "                remove_mask[i] = row\n",
    "                if row in best_rows1:\n",
    "                    y_L_new[i] = best_preds1[np.where(best_rows1==row)]\n",
    "                else:\n",
    "                    y_L_new[i] = best_preds2[np.where(best_rows2==row)]\n",
    "                    \n",
    "            \n",
    "            print(y_L_new)\n",
    "            \n",
    "            # add to labeled sets\n",
    "            print(A_X_L.shape)\n",
    "            print(A_X_UU[best_rows,:].shape)\n",
    "            \n",
    "            A_X_L = np.vstack((A_X_L, A_X_UU[best_rows,:]))\n",
    "            print(A_X_L.shape)\n",
    "            B_X_L = np.vstack((B_X_L, B_X_UU[best_rows,:]))\n",
    "            \n",
    "            # Add labels########################\n",
    "            \n",
    "            # remove from unlabeled set\n",
    "            print(remove_mask.shape)\n",
    "            mask = np.ones((A_X_UU.shape[0],))\n",
    "            mask[remove_mask] = 0\n",
    "            print(A_X_UU.shape)\n",
    "            A_X_UU = A_X_UU[mask==1,:]\n",
    "            B_X_UU = B_X_UU[mask==1,:]\n",
    "            print(A_X_UU.shape)\n",
    "            \n",
    "            # replenish UU sets\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,2,3,4,5,5,5,5,5,6])\n",
    "y = np.array(list(set(x)))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False False False  True False False False  True\n",
      " False False  True False False False  True False False False False False\n",
      " False False False False False False  True False  True False False False\n",
      " False  True False False False  True False  True False False False  True\n",
      " False False False False  True False False  True  True False  True False\n",
      " False  True False False False False False False False  True False False\n",
      " False False False False  True  True  True False False False False False\n",
      " False False False False False False False False False  True False False\n",
      "  True False False False]\n",
      "[  0   7  11  14  18  30  32  37  41  43  47  52  55  56  58  61  69  76\n",
      "  77  78  93  96 101 104 118 134 135 139 141 143 153 155 168 170 171 173\n",
      " 181 184 197 200 201 203 206 211 212 214 221 224 227 231 232 239 242 245\n",
      " 248 252 254 258 263 267 268 269 270 272 276 282 283 286 291 294 295 302\n",
      " 312 314 315 320 327 335 339 343 349 351 353 357 358 362 366 383 395 397\n",
      " 401 404 409 410 415 417 424 425 431 432 433 435 439 443 450 451 457 458\n",
      " 463 464 467 469 470 471 472 474 475 476 484 489 496 505 510 511 513 514\n",
      " 517 521 522 524 539 550 551 554 556 558 561 565 576 597 601 606 608 615\n",
      " 617 619 620 624 634 635 636 637 645 648 651 664 665 666 670 671 672 674\n",
      " 675 676 683 684 685 686 690 691 693 703 707 712 724 738 742 747 749 751\n",
      " 754 759 760 763 769 774 777 778 781 785 786 795 798 799 802 805 806 815\n",
      " 816 818 820 822 824 828 832 835 844 846 848 854 855 857 861 862 863 869\n",
      " 872 882 884 895 897 898 903 910 911 912 913 914 918 919 923 924 930 933\n",
      " 936 937 940 952 957 968 972 984 986]\n",
      "(60,)\n",
      "(60,)\n",
      "(90,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "(16, 39223)\n",
      "(90, 39223)\n",
      "(106, 39223)\n",
      "(90,)\n",
      "(243, 39223)\n",
      "(153, 39223)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [106, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-229-8f368c8e1485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMVtest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMVCoTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mMVtest1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewsA_X_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsA_y_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsB_X_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsB_y_train_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsA_X_train_U\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsB_X_train_U\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-227-7622d1f5c4a1>\u001b[0m in \u001b[0;36mfit_full\u001b[1;34m(self, A_X_L, A_y_L, B_X_L, B_y_L, A_X_U, B_X_U, n, p, max_iters, seed)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# fit h1 on the labeled data A_X_L\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_X_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_y_L\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;31m# fit h2 on labeled data B_X_L\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \"\"\"\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0;32m    185\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [106, 16]"
     ]
    }
   ],
   "source": [
    "MVtest1 = MVCoTrain()\n",
    "MVtest1.fit_full(newsA_X_train_L, newsA_y_train_L, newsB_X_train_L, newsB_y_train_L, newsA_X_train_U, newsB_X_train_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-ce74ea934e25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewsA_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(newsA_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50  1\n",
       "0  1   85  66  29    0  26.6  0.351  31  0\n",
       "1  8  183  64   0    0  23.3  0.672  32  1\n",
       "2  1   89  66  23   94  28.1  0.167  21  0\n",
       "3  0  137  40  35  168  43.1  2.288  33  1\n",
       "4  5  116  74   0    0  25.6  0.201  30  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"Diabetes_Dataset.csv\")\n",
    "full_labels = full_data['1']\n",
    "full_data.head()\n",
    "full_data = full_data.drop('1',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50\n",
       "0  1   85  66  29    0  26.6  0.351  31\n",
       "1  8  183  64   0    0  23.3  0.672  32\n",
       "2  1   89  66  23   94  28.1  0.167  21\n",
       "3  0  137  40  35  168  43.1  2.288  33\n",
       "4  5  116  74   0    0  25.6  0.201  30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = full_data.as_matrix()\n",
    "Y = full_labels.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into two groups (\"views\")\n",
    "Lsize = 20\n",
    "X_train_L = X_train[:Lsize,:]\n",
    "X_train_U = X_train[Lsize:,:]\n",
    "y_train_L = y_train[:Lsize]\n",
    "y_train_U = np.zeros_like(y_train[Lsize:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8)\n",
      "(670, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_L.shape)\n",
    "print(X_train_U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy iter 1 = \n",
      "0.675324675325\n",
      "(60,)\n",
      "(60,)\n",
      "Accuracy iter 2 = \n",
      "0.701298701299\n",
      "(60,)\n",
      "(60,)\n",
      "(553, 8)\n",
      "(140, 8)\n",
      "(140,)\n",
      "Accuracy iter 3 = \n",
      "0.753246753247\n",
      "(60,)\n",
      "(60,)\n",
      "(496, 8)\n",
      "(200, 8)\n",
      "(200,)\n",
      "Accuracy iter 4 = \n",
      "0.727272727273\n",
      "(60,)\n",
      "(60,)\n",
      "(441, 8)\n",
      "(260, 8)\n",
      "(260,)\n",
      "Accuracy iter 5 = \n",
      "0.701298701299\n",
      "(60,)\n",
      "(60,)\n",
      "(383, 8)\n",
      "(320, 8)\n",
      "(320,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# test fitting to a single view\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 1 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "# print(X_train_U.shape)\n",
    "\n",
    "# Iter 2\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 2 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "\n",
    "# Iter 3\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 3 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "\n",
    "# Iter 4\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 4 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)\n",
    "\n",
    "# Iter 5\n",
    "\n",
    "gnb.fit(X_train_L, y_train_L)\n",
    "probs = gnb.predict_proba(X_train_U)\n",
    "y_pred = gnb.predict(X_train_U)\n",
    "probs_class0 = probs[y_pred==0][:,0]\n",
    "probs_class1 = probs[y_pred==1][:,1]\n",
    "print(\"Accuracy iter 5 = \")\n",
    "print(accuracy_score(y_test,gnb.predict(X_test)))\n",
    "n = 30\n",
    "new_labels = np.transpose(np.hstack([np.zeros(n,),np.ones(n,)]))\n",
    "print(new_labels.shape)\n",
    "topN_class0 = np.argsort(probs_class0)[-n:]\n",
    "topN_class1 = np.argsort(probs_class1)[-n:]\n",
    "top2N_class = np.transpose(np.hstack([topN_class0, topN_class1]))\n",
    "print(top2N_class.shape)\n",
    "# add these to the labeled set\n",
    "# print(X_train_L.shape)\n",
    "# print(X_train_U[topN_class0,:].shape)\n",
    "# print(X_train_U[topN_class1,:].shape)\n",
    "X_train_L = np.vstack([X_train_L,X_train_U[topN_class0,:],X_train_U[topN_class1,:]])\n",
    "\n",
    "y_train_L = np.hstack([y_train_L,new_labels])\n",
    "\n",
    "X_train_U = np.delete(X_train_U,top2N_class.T,0)\n",
    "print(X_train_U.shape)\n",
    "print(X_train_L.shape)\n",
    "print(y_train_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "class CoTrainSingleView:\n",
    "    def __init__(self):\n",
    "        gnb1 = GaussianNB()\n",
    "        \n",
    "    def fit_full(self,X_L,y_L,X_U):\n",
    "        # fit on the labeled data\n",
    "        gnb1.fit(X_L,y_L)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
